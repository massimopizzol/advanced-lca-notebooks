{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a more complex case. Involves varying multiple parameters together and understanding which parameter is the one with the largest influence on results. This translates into a large simulation testing the various possibilities. One could use brute force and test all possible combinations of all parameters, and then run a regression on the results where the dependent variable is the impact of the system and the independent variables are the parameters. However, calculating a result for every possible combination might end up taking too much computation time, especially if the number of tested variables is high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis\n",
    "The content below shows how to perform a simple Global Sensitivity Analysis (GSA) for a example product system of a biobased product and using correlation analysis to quantify the defree of sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import brightway2.5 packages\n",
    "import bw2calc as bc\n",
    "import bw2data as bd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from lci_to_bw2 import * # import all the functions of this module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 9 object(s):\n",
       "\tALIGNED-biob-prod-dummy\n",
       "\tSAtestdb\n",
       "\tbiosphere3\n",
       "\tecoinvent 3.9.1 conseq\n",
       "\texldb\n",
       "\tgsa_db\n",
       "\tsa_db\n",
       "\ttestbiosphere\n",
       "\ttestdb"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.projects.set_current('advlca25') # Still working in the same project\n",
    "bd.databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing data about a fictional (\"dummy\") product system for a biobased product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dummy product system\n",
    "\n",
    "# import data from csv\n",
    "\n",
    "#mydata = pd.read_csv('LCI1-bw-format.csv', header = 0, sep = \",\") # using csv file avoids encoding problem\n",
    "mydata = pd.read_csv('ALIGNED-LCI-biobased-product-dummy.csv', header = 0, sep = \",\") # using csv file avoids encoding problem\n",
    "mydata.head()\n",
    "\n",
    "# keep only the columns not needed\n",
    "mydb = mydata[['Activity database','Activity code','Activity name','Activity unit','Activity type',\n",
    "               'Exchange database','Exchange input','Exchange amount','Exchange unit','Exchange type',\n",
    "               'Exchange uncertainty type','Exchange loc','Exchange scale','Exchange negative', 'Exchange minimum', 'Exchange maximum', \n",
    "               'Simapro name',\t'Simapro unit', 'Simapro type']].copy()\n",
    "\n",
    "mydb['Exchange uncertainty type'] = mydb['Exchange uncertainty type'].fillna(0).astype(int) # uncertainty as integers\n",
    "# Note: to avoid having both nan and values in the uncertainty column I use zero as default\n",
    "\n",
    "#print(mydb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not able to determine geocollections for all datasets. This database is not ready for regionalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 1752.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vacuuming database \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary in bw format and write database to disk. \n",
    "# Shut down all other notebooks using the same project before doing this\n",
    "bw2_db = lci_to_bw2(mydb) # a function from the lci_to_bw2 module\n",
    "\n",
    "# write database\n",
    "bd.Database('ALIGNED-biob-prod-dummy').write(bw2_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product system includes different activities such as the production, use, and end of life of the biobased product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Biomass-processing' (kilogram, None, None) 403a5c32-c769-46fc-8b9a-74b8eb3c79d1\n",
      "'Biobased-product-manufacturing' (kilogram, None, None) a37d149a-6508-4563-8af6-e5a39b4176df\n",
      "'Biomass-growth' (kilogram, None, None) a7d34649-9c10-4423-bac3-ecab9b43b20c\n",
      "'Biobased-product-use' (year, None, None) f9eabf64-b899-40c0-9f9f-2009dbb0a0b2\n",
      "'Biobased-product-eol' (kilogram, None, None) c8301e73-d521-4a89-998b-30b7e7751011\n"
     ]
    }
   ],
   "source": [
    "# check what foreground activities are included\n",
    "for act in bd.Database('ALIGNED-biob-prod-dummy'):\n",
    "    print(act, act['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Biobased-product-use',\n",
       " 'unit': 'year',\n",
       " 'type': 'process',\n",
       " 'database': 'ALIGNED-biob-prod-dummy',\n",
       " 'code': 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2',\n",
       " 'id': 23611}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More info \n",
    "myact = bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2') # Biobased-product-use\n",
    "myact._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': ('ALIGNED-biob-prod-dummy', 'a37d149a-6508-4563-8af6-e5a39b4176df'),\n",
       " 'amount': 50.0,\n",
       " 'unit': 'kilogram',\n",
       " 'type': 'technosphere',\n",
       " 'uncertainty type': 4,\n",
       " 'minimum': 37.5,\n",
       " 'maximum': 62.5,\n",
       " 'Simapro name': 'Biobased-product-manufacturing',\n",
       " 'Simapro unit': 'kg',\n",
       " 'output': ('ALIGNED-biob-prod-dummy', 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncertainty is also there\n",
    "list(myact.exchanges())[1]._data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate a static climate impact score for the fictional biobased product, to be used for reference later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.67148771458245\n"
     ]
    }
   ],
   "source": [
    "# calculation of static LCA score\n",
    "mymethod = ('IPCC 2013', 'climate change', 'global warming potential (GWP100)')\n",
    "myact = bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2') # Biobased-product-use\n",
    "functional_unit = {myact: 1}\n",
    "LCA = bc.LCA(functional_unit, mymethod)\n",
    "LCA.lci()\n",
    "LCA.lcia()\n",
    "print(LCA.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now perform global sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure is in three steps.\n",
    "\n",
    "1) A set of model input parameters is chosen. These are **values of specific exchanges**. A sample of values is produced for each model input, in this case, only 5 values.\n",
    "2) A simulation is performed. Initial prameter values are substituted with those in the sample, iteratively, and new model outputs, that are LCA scores, are calculated.\n",
    "3) A correlation is estimated between model input values and output values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "A sample of values for each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be done in many ways, here very basic using lists.\n",
    "par1_values = [-1.25, -1.10, -1, -0.9, -0.75] # In bomass growth, value of CO2 uptake\n",
    "par2_values = [0.1, 0.3, 0.5, 0.7, 0.9] # In biomass processing, amount of energy used.\n",
    "par3_values = [20,30,40,50,60]  # In use of product, amount of manufactured product needed\n",
    "par4_values = [1.25, 1.10, 1, 0.9, 0.75] # In use of product, amount of manufactured product needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate the values to specific exchanges using the coordinates (column and row) of the technosphere (A) and biosphere (B) matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_samples = [(('ALIGNED-biob-prod-dummy', 'a7d34649-9c10-4423-bac3-ecab9b43b20c'), \n",
    "  ('biosphere3', '349b29d1-3e58-4c66-98b9-9d1a076efd2e'), par1_values), # In bomass growth, value of CO2 uptake\n",
    "(('ALIGNED-biob-prod-dummy', '403a5c32-c769-46fc-8b9a-74b8eb3c79d1'),\n",
    " ('ecoinvent 3.9 conseq', 'f4dc7d2b1d70e6c0f929ec5231c085e0'), par2_values), # In biomass processing, amount of energy used.\n",
    " (('ALIGNED-biob-prod-dummy', 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2'),\n",
    "  ('ALIGNED-biob-prod-dummy', 'a37d149a-6508-4563-8af6-e5a39b4176df'), par3_values), # In use of product, amount of manufactured product needed\n",
    "  (('ALIGNED-biob-prod-dummy', 'c8301e73-d521-4a89-998b-30b7e7751011'),\n",
    "   ('biosphere3', '349b29d1-3e58-4c66-98b9-9d1a076efd2e'), par4_values)] # In end of life, amount of CO2 released"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (technical note)\n",
    "\n",
    "We can do the same in a more elegant way, taking the data directly from the BW database that we just created..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In biomass growth, value of CO2 uptake\n",
    "par1 = list(bd.Database('ALIGNED-biob-prod-dummy').get('a7d34649-9c10-4423-bac3-ecab9b43b20c').exchanges())[3]\n",
    "# In biomass processing, amount of energy used.\n",
    "par2 = list(bd.Database('ALIGNED-biob-prod-dummy').get('403a5c32-c769-46fc-8b9a-74b8eb3c79d1').exchanges())[1]\n",
    "# In use of product, amount of manufactured product needed\n",
    "par3 = list(bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2').exchanges())[1]\n",
    "# In use of product, amount of manufactured product needed\n",
    "par4 = list(bd.Database('ALIGNED-biob-prod-dummy').get('c8301e73-d521-4a89-998b-30b7e7751011').exchanges())[2]\n",
    "\n",
    "n_iter = 5\n",
    "param_samples = [(par1['output'],par1['input'], par1.random_sample(n = n_iter)),\n",
    "                 (par2['output'],par2['input'], par2.random_sample(n = n_iter)),\n",
    "                 (par3['output'],par3['input'], par3.random_sample(n = n_iter)),\n",
    "                 (par4['output'],par4['input'], par4.random_sample(n = n_iter))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the samples obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ALIGNED-biob-prod-dummy', 'a7d34649-9c10-4423-bac3-ecab9b43b20c'),\n",
       "  ('biosphere3', '349b29d1-3e58-4c66-98b9-9d1a076efd2e'),\n",
       "  array([-0.94008983, -0.8699042 , -1.24487299, -0.97397597, -1.1907887 ])),\n",
       " (('ALIGNED-biob-prod-dummy', '403a5c32-c769-46fc-8b9a-74b8eb3c79d1'),\n",
       "  ('ecoinvent 3.9.1 conseq', 'f4dc7d2b1d70e6c0f929ec5231c085e0'),\n",
       "  array([0.48602327, 0.52151973, 0.49501432, 0.606012  , 0.45231842])),\n",
       " (('ALIGNED-biob-prod-dummy', 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2'),\n",
       "  ('ALIGNED-biob-prod-dummy', 'a37d149a-6508-4563-8af6-e5a39b4176df'),\n",
       "  array([44.96312104, 62.09817233, 44.62648947, 43.75094756, 53.85788237])),\n",
       " (('ALIGNED-biob-prod-dummy', 'c8301e73-d521-4a89-998b-30b7e7751011'),\n",
       "  ('biosphere3', '349b29d1-3e58-4c66-98b9-9d1a076efd2e'),\n",
       "  array([1.23169336, 1.11548435, 0.78135885, 1.02840774, 1.02881701]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "\n",
    "Iteration through all parameter samples. Input values are replaced and new impact scores are calculated at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 -0.9400898298528071\n",
      "-0.5 -0.48602326965975096\n",
      "-50.0 -44.96312104319368\n",
      "1.0 1.2316933648038761\n",
      "* * *\n",
      "-1.0 -0.8699042041934981\n",
      "-0.5 -0.5215197291697707\n",
      "-50.0 -62.098172327364686\n",
      "1.0 1.1154843489158166\n",
      "* * *\n",
      "-1.0 -1.2448729915176875\n",
      "-0.5 -0.49501432255318534\n",
      "-50.0 -44.626489467940324\n",
      "1.0 0.7813588464915562\n",
      "* * *\n",
      "-1.0 -0.9739759715538552\n",
      "-0.5 -0.6060119983235702\n",
      "-50.0 -43.75094755949158\n",
      "1.0 1.0284077385584582\n",
      "* * *\n",
      "-1.0 -1.1907886987662732\n",
      "-0.5 -0.4523184220355385\n",
      "-50.0 -53.85788237085855\n",
      "1.0 1.028817007330332\n",
      "* * *\n"
     ]
    }
   ],
   "source": [
    "# testing the loop that will be used for the simulation, iterate through parameter values\n",
    "    \n",
    "for i in range(0,n_iter): # iterate 5 times...\n",
    "    for s in param_samples: # and for each paramater...\n",
    "        \n",
    "        # Get the 'id' using the activity object\n",
    "        col_id = bd.Database(s[0][0]).get(s[0][1]).id\n",
    "        row_id = bd.Database(s[1][0]).get(s[1][1]).id\n",
    "        \n",
    "        # Use the id and the mapping dictionaries to find matrix row and columns\n",
    "        if s[1][0] == \"biosphere3\":\n",
    "            col = LCA.activity_dict[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.biosphere_dict[row_id] # find row index of B matrix for the exchange\n",
    "            print(LCA.biosphere_matrix[row,col], s[2][i]) # print the initial and final value (to be substituted) ????\n",
    "        \n",
    "        else:\n",
    "            col = LCA.activity_dict[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.activity_dict[row_id] # find row index of A matrix for the exchange\n",
    "            print(LCA.technosphere_matrix[row,col], -s[2][i]) # CHANGE OF SIGN!\n",
    "        \n",
    "    print(\"* * *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.47433450820517\n",
      "148.60406051512743\n",
      "97.67956238263707\n",
      "114.92783075977592\n",
      "123.37221292412063\n"
     ]
    }
   ],
   "source": [
    "# Implementing the loop\n",
    "\n",
    "GSA_value_results = []\n",
    "\n",
    "for i in range(0,n_iter): \n",
    "    for s in param_samples:\n",
    "        col_id = bd.Database(s[0][0]).get(s[0][1]).id\n",
    "        row_id = bd.Database(s[1][0]).get(s[1][1]).id\n",
    "        \n",
    "        if s[1][0] == \"biosphere3\":\n",
    "            col = LCA.activity_dict[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.biosphere_dict[row_id] # find row index of B matrix for the exchange\n",
    "            LCA.biosphere_matrix[row,col] = s[2][i] # substitute the value\n",
    "        else:\n",
    "            col = LCA.activity_dict[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.activity_dict[row_id] # find row index of A matrix for the exchange\n",
    "            LCA.technosphere_matrix[row,col] = -s[2][i] # substitute the value\n",
    "                \n",
    "    LCA.redo_lci() # uses the new A matrix\n",
    "    LCA.lcia()\n",
    "    print(LCA.score)\n",
    "    GSA_value_results.append(LCA.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "\n",
    "Now we have both the input and output values and we can look at their correlation.\n",
    "\n",
    "To estimate the degree of correlation use a Pearson coefficient of linear relationship between two sets of values.\n",
    "\n",
    "See here for info: \n",
    "https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n",
    "\n",
    "This approach has for example been used in:\n",
    "\n",
    "_Kim, A., Mutel, C., Froemelt, A., 2021. Robust high-dimensional screening. Environmental Modelling & Software 105270._ https://doi.org/10.1016/j.envsoft.2021.105270\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par1</th>\n",
       "      <th>par2</th>\n",
       "      <th>par3</th>\n",
       "      <th>par4</th>\n",
       "      <th>GWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>par1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.464900</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>0.789531</td>\n",
       "      <td>0.769329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>par2</th>\n",
       "      <td>0.464900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.259602</td>\n",
       "      <td>-0.007492</td>\n",
       "      <td>-0.051742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>par3</th>\n",
       "      <td>0.316500</td>\n",
       "      <td>-0.259602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258492</td>\n",
       "      <td>0.801096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>par4</th>\n",
       "      <td>0.789531</td>\n",
       "      <td>-0.007492</td>\n",
       "      <td>0.258492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GWI</th>\n",
       "      <td>0.769329</td>\n",
       "      <td>-0.051742</td>\n",
       "      <td>0.801096</td>\n",
       "      <td>0.766056</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          par1      par2      par3      par4       GWI\n",
       "par1  1.000000  0.464900  0.316500  0.789531  0.769329\n",
       "par2  0.464900  1.000000 -0.259602 -0.007492 -0.051742\n",
       "par3  0.316500 -0.259602  1.000000  0.258492  0.801096\n",
       "par4  0.789531 -0.007492  0.258492  1.000000  0.766056\n",
       "GWI   0.769329 -0.051742  0.801096  0.766056  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcualte correlation\n",
    "\n",
    "corr_data = pd.DataFrame([i[2] for i in param_samples], index = ['par1','par2', 'par3', 'par4']).T\n",
    "corr_data['GWI'] = GSA_value_results\n",
    "corr_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this specific case \"par3\"  is the parameter to which the results are most sensitive to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exchange: 50.0 kilogram 'Biobased-product-manufacturing' (kilogram, None, None) to 'Biobased-product-use' (year, None, None)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what was \"par3\" again?\n",
    "par3 # amount of manufactured product need din the use stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAST\n",
    "\n",
    "The content below shows how to perform a simple Global Sensitivity Analysis (GSA) applying the FAST, a variance-based sensitivity analysis method, for an example product system of a biobased product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import bw2calc as bc\n",
    "import bw2data as bd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from lci_to_bw2 import * # import all the functions of this module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a project with ecoinvent v.3.9.1 consequential system model\n",
    "bd.projects.set_current('advlca25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing data about a fictional (\"dummy\") product system for a biobased product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dummy product system\n",
    "\n",
    "# import data from csv\n",
    "mydata = pd.read_csv('ALIGNED-LCI-biobased-product-dummy.csv', header = 0, sep = \",\") # using csv file avoids encoding problem\n",
    "mydata.head()\n",
    "\n",
    "# keep only the columns not needed\n",
    "mydb = mydata[['Activity database','Activity code','Activity name','Activity unit','Activity type',\n",
    "               'Exchange database','Exchange input','Exchange amount','Exchange unit','Exchange type',\n",
    "               'Exchange uncertainty type','Exchange loc','Exchange scale','Exchange negative', 'Exchange minimum', 'Exchange maximum', \n",
    "               'Simapro name',\t'Simapro unit', 'Simapro type']].copy()\n",
    "\n",
    "mydb['Exchange uncertainty type'] = mydb['Exchange uncertainty type'].fillna(0).astype(int) # uncertainty as integers\n",
    "# Note: to avoid having both nan and values in the uncertainty column I use zero as default\n",
    "\n",
    "#print(mydb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not able to determine geocollections for all datasets. This database is not ready for regionalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 3004.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vacuuming database \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary in bw format and write database to disk. \n",
    "# Shut down all other notebooks using the same project before doing this\n",
    "bw2_db = lci_to_bw2(mydb) # a function from the lci_to_bw2 module\n",
    "\n",
    "# write database\n",
    "bd.Database('ALIGNED-biob-prod-dummy').write(bw2_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product system includes different activities such as the production, use, and end of life of the biobased product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Biobased-product-use' (year, None, None) f9eabf64-b899-40c0-9f9f-2009dbb0a0b2\n",
      "'Biomass-growth' (kilogram, None, None) a7d34649-9c10-4423-bac3-ecab9b43b20c\n",
      "'Biomass-processing' (kilogram, None, None) 403a5c32-c769-46fc-8b9a-74b8eb3c79d1\n",
      "'Biobased-product-manufacturing' (kilogram, None, None) a37d149a-6508-4563-8af6-e5a39b4176df\n",
      "'Biobased-product-eol' (kilogram, None, None) c8301e73-d521-4a89-998b-30b7e7751011\n"
     ]
    }
   ],
   "source": [
    "# check what foreground activities are included\n",
    "for act in bd.Database('ALIGNED-biob-prod-dummy'):\n",
    "    print(act, act['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Biobased-product-use',\n",
       " 'unit': 'year',\n",
       " 'type': 'process',\n",
       " 'database': 'ALIGNED-biob-prod-dummy',\n",
       " 'code': 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2',\n",
       " 'id': 23611}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More info \n",
    "myact = bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2') # Biobased-product-use\n",
    "myact._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': ('ALIGNED-biob-prod-dummy', 'a37d149a-6508-4563-8af6-e5a39b4176df'),\n",
       " 'amount': 50.0,\n",
       " 'unit': 'kilogram',\n",
       " 'type': 'technosphere',\n",
       " 'uncertainty type': 4,\n",
       " 'minimum': 37.5,\n",
       " 'maximum': 62.5,\n",
       " 'Simapro name': 'Biobased-product-manufacturing',\n",
       " 'Simapro unit': 'kg',\n",
       " 'output': ('ALIGNED-biob-prod-dummy', 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2')}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncertainty is also there\n",
    "list(myact.exchanges())[1]._data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate a static climate impact score for the fictional biobased product, to be used for reference later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.67148771458245\n"
     ]
    }
   ],
   "source": [
    "# calculation of static LCA score\n",
    "mymethod = ('IPCC 2013', 'climate change', 'global warming potential (GWP100)')\n",
    "myact = bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2') # Biobased-product-use\n",
    "functional_unit = {myact: 1}\n",
    "LCA = bc.LCA(functional_unit, mymethod)\n",
    "LCA.lci()\n",
    "LCA.lcia()\n",
    "print(LCA.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now perform sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure is in three steps.\n",
    "\n",
    "1) A set of model input parameters is chosen. These are **values of specific exchanges**. A sample of values is produced for each model input **using a specific and efficient sampling design** (the **\"problem\"** below)\n",
    "2) A simulation is performed. Initial prameter values are substituted with those in the sample, iteratively, and new model outputs, that are LCA scores, are calculated.\n",
    "3) **A sensitivity index is calculated** using model input values (the \"problem\") and output values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "Obtain a sample of values for each parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a  pseudo-random sample obtained using a sampling method from the SALib package on the problem previously defined.\n",
    "\n",
    "it is defined as a __FAST__ sample (\"Fourier Amplitude Sensitivity Analysis\"), another alternative to Sobol method.\n",
    "\n",
    "Sobol and FAST sampling methods use different pseudo-random patterns to cover the space of parameters, and different calculations for the sensitivity indices.\n",
    "\n",
    "Besides these differences, the (extended) FAST method is, just like the Sobol one, a variance-based method for sensitivity analysis. It provides the same information as the Sobol method but with higher computational efficiency.\n",
    "\n",
    "For further information and comparison see: \n",
    "\n",
    "_Saltelli, A.; Tarantola, S.; Chan, K. P. S. A Quantitative Model-Independent Method for Global Sensitivity Analysis of Model Output. Technometrics 1999, 41 (1), 39–56._ https://doi.org/10.1080/00401706.1999.10485594.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to import the SALib library and relaive methods for sensitvity analysis\n",
    "# do 'pip install SALib' in the brightway environment\n",
    "\n",
    "from SALib.sample import saltelli\n",
    "from SALib.sample import fast_sampler\n",
    "from SALib.analyze import sobol\n",
    "from SALib.analyze import fast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the \"problem\" for the GSA analysis as indicated in the SALib library.\n",
    "Uniform distributions for the uncertainty of for each input parameter are here assumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = { 'num_vars': 4, # number of variables\n",
    "            'names': ['par1', 'par2', 'par3', 'par4'], # names of variables, same as parameters\n",
    "            'bounds': [[-1.25, -0.75], # careful here to what is the lower bound with negative values...\n",
    "                       [0.1, 0.9],  \n",
    "                       [20, 60],\n",
    "                       [0.75, 1.25]] ,\n",
    "           'dists':[\"unif\",\"unif\",\"unif\",\"unif\"] } # all uniform distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.83186667,  0.76901333, 53.45066667,  1.16813333],\n",
       "       [-0.78813333,  0.77701333, 54.25066667,  1.18313333],\n",
       "       [-0.90813333,  0.78501333, 55.05066667,  1.19813333],\n",
       "       ...,\n",
       "       [-1.13018109,  0.31571026, 31.98551281,  1.21481891],\n",
       "       [-1.13518109,  0.29971026, 30.78551281,  1.09481891],\n",
       "       [-1.14018109,  0.28371026, 29.58551281,  0.97481891]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FAST sampler creates N*P parameters sets with N=sample size, P = number of parameters\n",
    "param_values_FAST = fast_sampler.sample(problem, 200)\n",
    "print(param_values_FAST.shape)\n",
    "\n",
    "param_values_FAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate the values to specific exchanges using the coordinates (column and row) of the technosphere (A) and biosphere (B) matrices, taking the data directly from the BW database that we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In biomass growth, value of CO2 uptake\n",
    "par1 = list(bd.Database('ALIGNED-biob-prod-dummy').get('a7d34649-9c10-4423-bac3-ecab9b43b20c').exchanges())[3]\n",
    "# In biomass processing, amount of energy used.\n",
    "par2 = list(bd.Database('ALIGNED-biob-prod-dummy').get('403a5c32-c769-46fc-8b9a-74b8eb3c79d1').exchanges())[1]\n",
    "# In use of product, amount of manufactured product needed\n",
    "par3 = list(bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2').exchanges())[1]\n",
    "# In use of product, amount of manufactured product needed\n",
    "par4 = list(bd.Database('ALIGNED-biob-prod-dummy').get('c8301e73-d521-4a89-998b-30b7e7751011').exchanges())[2]\n",
    "\n",
    "n_iter = len(param_values_FAST)\n",
    "param_samples = [(par1['output'],par1['input'], [i[0] for i in param_values_FAST]),\n",
    "                 (par2['output'],par2['input'], [i[1] for i in param_values_FAST]),\n",
    "                 (par3['output'],par3['input'], [i[2] for i in param_values_FAST]),\n",
    "                 (par4['output'],par4['input'], [i[3] for i in param_values_FAST])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "\n",
    "Iteration through all parameter samples. New LCA scores are calculated for each combination of values.\n",
    "\n",
    "With 800 iterations, **this will take some time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the loop\n",
    "\n",
    "GSA_value_results = []\n",
    "\n",
    "for i in range(0,len(param_values_FAST)): \n",
    "    for s in param_samples:\n",
    "        # Get the 'id' using the activity object\n",
    "        col_id = bd.Database(s[0][0]).get(s[0][1]).id\n",
    "        row_id = bd.Database(s[1][0]).get(s[1][1]).id\n",
    "        \n",
    "        # Use the id and the mapping dictionaries to find matrix row and columns\n",
    "        if s[1][0] == \"biosphere3\":\n",
    "            col = LCA.activity_dict[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.biosphere_dict[row_id] # find row index of B matrix for the exchange\n",
    "            LCA.biosphere_matrix[row,col] = s[2][i] # substitute the value\n",
    "        else:\n",
    "            col = LCA.activity_dict[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.activity_dict[row_id] # find row index of A matrix for the exchange\n",
    "            LCA.technosphere_matrix[row,col] = -s[2][i] # substitute the value\n",
    "        \n",
    "    LCA.redo_lci() # uses the new A matrix\n",
    "    LCA.lcia()\n",
    "    #print(LCA.score)\n",
    "    GSA_value_results.append(LCA.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "\n",
    "Now we have both the input and output values and we can feed the problem and the results to the Sobol function to obtain the FAST indices.\n",
    "\n",
    "First we look at the parameters and the result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par0</th>\n",
       "      <th>par1</th>\n",
       "      <th>par2</th>\n",
       "      <th>par3</th>\n",
       "      <th>GWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.831867</td>\n",
       "      <td>0.769013</td>\n",
       "      <td>53.450667</td>\n",
       "      <td>1.168133</td>\n",
       "      <td>139.740957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.788133</td>\n",
       "      <td>0.777013</td>\n",
       "      <td>54.250667</td>\n",
       "      <td>1.183133</td>\n",
       "      <td>142.887983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.908133</td>\n",
       "      <td>0.785013</td>\n",
       "      <td>55.050667</td>\n",
       "      <td>1.198133</td>\n",
       "      <td>141.563444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.028133</td>\n",
       "      <td>0.793013</td>\n",
       "      <td>55.850667</td>\n",
       "      <td>1.213133</td>\n",
       "      <td>140.143166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.148133</td>\n",
       "      <td>0.801013</td>\n",
       "      <td>56.650667</td>\n",
       "      <td>1.228133</td>\n",
       "      <td>138.627151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.231867</td>\n",
       "      <td>0.809013</td>\n",
       "      <td>57.450667</td>\n",
       "      <td>1.243133</td>\n",
       "      <td>138.057169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.111867</td>\n",
       "      <td>0.817013</td>\n",
       "      <td>58.250667</td>\n",
       "      <td>1.241867</td>\n",
       "      <td>142.540932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.991867</td>\n",
       "      <td>0.825013</td>\n",
       "      <td>59.050667</td>\n",
       "      <td>1.226867</td>\n",
       "      <td>146.434289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.871867</td>\n",
       "      <td>0.833013</td>\n",
       "      <td>59.850667</td>\n",
       "      <td>1.211867</td>\n",
       "      <td>150.423909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.751867</td>\n",
       "      <td>0.841013</td>\n",
       "      <td>59.349333</td>\n",
       "      <td>1.196867</td>\n",
       "      <td>152.500799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       par0      par1       par2      par3         GWI\n",
       "0 -0.831867  0.769013  53.450667  1.168133  139.740957\n",
       "1 -0.788133  0.777013  54.250667  1.183133  142.887983\n",
       "2 -0.908133  0.785013  55.050667  1.198133  141.563444\n",
       "3 -1.028133  0.793013  55.850667  1.213133  140.143166\n",
       "4 -1.148133  0.801013  56.650667  1.228133  138.627151\n",
       "5 -1.231867  0.809013  57.450667  1.243133  138.057169\n",
       "6 -1.111867  0.817013  58.250667  1.241867  142.540932\n",
       "7 -0.991867  0.825013  59.050667  1.226867  146.434289\n",
       "8 -0.871867  0.833013  59.850667  1.211867  150.423909\n",
       "9 -0.751867  0.841013  59.349333  1.196867  152.500799"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organize data first to give a look at what we have done: a sample of input values and a corresponding output value\n",
    "fast_data = pd.DataFrame([i[2] for i in param_samples], index = ['par0','par1', 'par2', 'par3']).T\n",
    "fast_data['GWI'] = GSA_value_results\n",
    "fast_data.head(10) # show only the first ten samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the SI index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            S1        ST   S1_conf   ST_conf\n",
      "par1  0.025341  0.029323  0.063048  0.091228\n",
      "par2  0.000112  0.001037  0.075100  0.083699\n",
      "par3  0.821179  0.825417  0.072916  0.091960\n",
      "par4  0.157746  0.160019  0.073431  0.084295\n"
     ]
    }
   ],
   "source": [
    "si = fast.analyze(problem, np.array(GSA_value_results), print_to_console=True) # must use np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this specific case \"par3\"  is the parameter to which the results are most sensitive to, this because it has the highest value for \"S1\" which is the first order effect.\n",
    "\n",
    "This is determined with relativelygood confidence as the error (value of \"S1_conf\") is small compared to the coefficient.\n",
    "\n",
    "Note also that \"par3\" is also the parameter withi highest sensitivity in the total model, i.e. when in combinatino with other parameters, as observed by the highest value of \"ST\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exchange: 50.0 kilogram 'Biobased-product-manufacturing' (kilogram, None, None) to 'Biobased-product-use' (year, None, None)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this specific case \"par3\" is the parameter to which the results ar emost sensitive to, and values have high confidente (small error)\n",
    "# what was \"par3\" again?\n",
    "par3 # amount of manufactured product need din the use stage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
