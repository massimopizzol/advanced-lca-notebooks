{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a more complex case. Involves varying multiple parameters together and understanding which parameter is the one with the largest influence on results. This translates into a large simulation testing the various possibilities. One could use brute force and test all possible combinations of all parameters, and then run a regression on the results where the dependent variable is the impact of the system and the independent variables are the parameters. However, calculating a result for every possible combination might end up taking too much computation time, especially if the number of tested variables is high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis\n",
    "The content below shows how to perform a simple Global Sensitivity Analysis (GSA) for a example product system of a biobased product and using correlation analysis to quantify the defree of sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import brightway2.5 packages\n",
    "import bw2calc as bc\n",
    "import bw2data as bd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from lci_to_bw2 import * # import all the functions of this module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 8 object(s):\n",
       "\tALIGNED-biob-prod-dummy\n",
       "\tecoinvent-3.11-biosphere\n",
       "\tecoinvent-3.11-consequential\n",
       "\texldb\n",
       "\tlccfg\n",
       "\tlcctestdb\n",
       "\ttestbiosphere\n",
       "\ttestdb"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.projects.set_current('advlca25') # Still working in the same project\n",
    "bd.databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing data about a fictional (\"dummy\") product system for a biobased product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dummy product system\n",
    "\n",
    "# import data from csv\n",
    "\n",
    "#mydata = pd.read_csv('LCI1-bw-format.csv', header = 0, sep = \",\") # using csv file avoids encoding problem\n",
    "mydata = pd.read_csv('ALIGNED-LCI-biobased-product-dummy.csv', header = 0, sep = \",\") # using csv file avoids encoding problem\n",
    "mydata.head()\n",
    "\n",
    "# keep only the columns not needed\n",
    "mydb = mydata[['Activity database','Activity code','Activity name','Activity unit','Activity type',\n",
    "               'Exchange database','Exchange input','Exchange amount','Exchange unit','Exchange type',\n",
    "               'Exchange uncertainty type','Exchange loc','Exchange scale','Exchange negative', 'Exchange minimum', 'Exchange maximum', \n",
    "               'Simapro name',\t'Simapro unit', 'Simapro type']].copy()\n",
    "\n",
    "mydb['Exchange uncertainty type'] = mydb['Exchange uncertainty type'].fillna(0).astype(int) # uncertainty as integers\n",
    "# Note: to avoid having both nan and values in the uncertainty column I use zero as default\n",
    "\n",
    "#print(mydb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m14:36:53\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mNot able to determine geocollections for all datasets. This database is not ready for regionalization.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 5/5 [00:00<00:00, 6683.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m14:36:53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mVacuuming database            \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary in bw format and write database to disk. \n",
    "# Shut down all other notebooks using the same project before doing this\n",
    "bw2_db = lci_to_bw2(mydb) # a function from the lci_to_bw2 module\n",
    "\n",
    "# write database\n",
    "bd.Database('ALIGNED-biob-prod-dummy').write(bw2_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product system includes different activities such as the production, use, and end of life of the biobased product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Biobased-product-eol' (kilogram, None, None) c8301e73-d521-4a89-998b-30b7e7751011\n",
      "'Biobased-product-manufacturing' (kilogram, None, None) a37d149a-6508-4563-8af6-e5a39b4176df\n",
      "'Biomass-growth' (kilogram, None, None) a7d34649-9c10-4423-bac3-ecab9b43b20c\n",
      "'Biomass-processing' (kilogram, None, None) 403a5c32-c769-46fc-8b9a-74b8eb3c79d1\n",
      "'Biobased-product-use' (year, None, None) f9eabf64-b899-40c0-9f9f-2009dbb0a0b2\n"
     ]
    }
   ],
   "source": [
    "# check what foreground activities are included\n",
    "for act in bd.Database('ALIGNED-biob-prod-dummy'):\n",
    "    print(act, act['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Biobased-product-use',\n",
       " 'unit': 'year',\n",
       " 'type': 'processwithreferenceproduct',\n",
       " 'database': 'ALIGNED-biob-prod-dummy',\n",
       " 'code': 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2',\n",
       " 'id': 158206687701803008}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More info \n",
    "myact = bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2') # Biobased-product-use\n",
    "myact._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': ('ALIGNED-biob-prod-dummy', 'a37d149a-6508-4563-8af6-e5a39b4176df'),\n",
       " 'amount': 50.0,\n",
       " 'unit': 'kilogram',\n",
       " 'type': 'technosphere',\n",
       " 'uncertainty type': 4,\n",
       " 'minimum': 37.5,\n",
       " 'maximum': 62.5,\n",
       " 'Simapro name': 'Biobased-product-manufacturing',\n",
       " 'Simapro unit': 'kg',\n",
       " 'output': ('ALIGNED-biob-prod-dummy', 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncertainty is also there\n",
    "list(myact.exchanges())[1]._data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate a nominal climate impact score for the fictional biobased product, to be used for reference later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180.28497357367445\n"
     ]
    }
   ],
   "source": [
    "# calculation of nominal LCA score\n",
    "mymethod = ('ecoinvent-3.11', 'IPCC 2021', 'climate change: fossil', 'global warming potential (GWP100)')\n",
    "myact = bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2') # Biobased-product-use\n",
    "functional_unit = {myact: 1}\n",
    "LCA = bc.LCA(functional_unit, mymethod)\n",
    "LCA.lci()\n",
    "LCA.lcia()\n",
    "print(LCA.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now perform global sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure is in three steps.\n",
    "\n",
    "1) A set of model input parameters is chosen. These are **values of specific exchanges**. A sample of values is produced for each model input, in this case, only 5 values.\n",
    "2) A simulation is performed. Initial prameter values are substituted with those in the sample, iteratively, and new model outputs, that are LCA scores, are calculated.\n",
    "3) A correlation is estimated between model input values and output values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "A sample of values for each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be done in many ways, here very basic using lists.\n",
    "par1_values = [-1.25, -1.10, -1, -0.9, -0.75] # In bomass growth, value of CO2 uptake\n",
    "par2_values = [0.1, 0.3, 0.5, 0.7, 0.9] # In biomass processing, amount of energy used.\n",
    "par3_values = [20,30,40,50,60]  # In use of product, amount of manufactured product needed\n",
    "par4_values = [1.25, 1.10, 1, 0.9, 0.75] # In use of product, amount of manufactured product needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate the values to specific exchanges using the coordinates (column and row) of the technosphere (A) and biosphere (B) matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_samples = [(('ALIGNED-biob-prod-dummy', 'a7d34649-9c10-4423-bac3-ecab9b43b20c'), \n",
    "  ('ecoinvent-3.11-biosphere','349b29d1-3e58-4c66-98b9-9d1a076efd2e'), par1_values), # In bomass growth, value of CO2 uptake\n",
    "(('ALIGNED-biob-prod-dummy', '403a5c32-c769-46fc-8b9a-74b8eb3c79d1'),\n",
    " ('ecoinvent-3.11-consequential','a69490974731f9da34043d5c926cd167'), par2_values), # In biomass processing, amount of energy used.\n",
    " (('ALIGNED-biob-prod-dummy', 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2'),\n",
    "  ('ALIGNED-biob-prod-dummy', 'a37d149a-6508-4563-8af6-e5a39b4176df'), par3_values), # In use of product, amount of manufactured product needed\n",
    "  (('ALIGNED-biob-prod-dummy', 'c8301e73-d521-4a89-998b-30b7e7751011'),\n",
    "   ('ecoinvent-3.11-biosphere','349b29d1-3e58-4c66-98b9-9d1a076efd2e'), par4_values)] # In end of life, amount of CO2 released"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (technical note)\n",
    "\n",
    "We can do the same in a more elegant way, taking the data directly from the BW database that we just created..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In biomass growth, value of CO2 uptake\n",
    "par1 = list(bd.Database('ALIGNED-biob-prod-dummy').get('a7d34649-9c10-4423-bac3-ecab9b43b20c').exchanges())[3]\n",
    "# In biomass processing, amount of energy used.\n",
    "par2 = list(bd.Database('ALIGNED-biob-prod-dummy').get('403a5c32-c769-46fc-8b9a-74b8eb3c79d1').exchanges())[1]\n",
    "# In use of product, amount of manufactured product needed\n",
    "par3 = list(bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2').exchanges())[1]\n",
    "# In use of product, amount of manufactured product needed\n",
    "par4 = list(bd.Database('ALIGNED-biob-prod-dummy').get('c8301e73-d521-4a89-998b-30b7e7751011').exchanges())[2]\n",
    "\n",
    "n_iter = 5\n",
    "param_samples = [(par1['output'],par1['input'], par1.random_sample(n = n_iter)),\n",
    "                 (par2['output'],par2['input'], par2.random_sample(n = n_iter)),\n",
    "                 (par3['output'],par3['input'], par3.random_sample(n = n_iter)),\n",
    "                 (par4['output'],par4['input'], par4.random_sample(n = n_iter))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the samples obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ALIGNED-biob-prod-dummy', 'a7d34649-9c10-4423-bac3-ecab9b43b20c'),\n",
       "  ('ecoinvent-3.11-biosphere', '349b29d1-3e58-4c66-98b9-9d1a076efd2e'),\n",
       "  array([-1.10034447, -1.07858308, -0.78085421, -1.07736422, -1.23161972])),\n",
       " (('ALIGNED-biob-prod-dummy', '403a5c32-c769-46fc-8b9a-74b8eb3c79d1'),\n",
       "  ('ecoinvent-3.11-consequential', 'a69490974731f9da34043d5c926cd167'),\n",
       "  array([0.49801342, 0.38347052, 0.5516293 , 0.45764931, 0.62401611])),\n",
       " (('ALIGNED-biob-prod-dummy', 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2'),\n",
       "  ('ALIGNED-biob-prod-dummy', 'a37d149a-6508-4563-8af6-e5a39b4176df'),\n",
       "  array([57.07401351, 44.62772923, 59.89983582, 44.52616595, 46.30428387])),\n",
       " (('ALIGNED-biob-prod-dummy', 'c8301e73-d521-4a89-998b-30b7e7751011'),\n",
       "  ('ecoinvent-3.11-biosphere', '349b29d1-3e58-4c66-98b9-9d1a076efd2e'),\n",
       "  array([0.96469963, 1.09797637, 1.24865035, 0.96165161, 1.22047394]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "\n",
    "Iteration through all parameter samples. Input values are replaced and new impact scores are calculated at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biosphere value: -1.0 | paramater value: -1.100344474923109\n",
      "technosphere value: -0.5 | paramater value: -0.49801342449399233\n",
      "technosphere value: -50.0 | paramater value: -57.07401351211584\n",
      "biosphere value: 1.0 | paramater value: 0.9646996339355052\n",
      "* * *\n",
      "biosphere value: -1.0 | paramater value: -1.0785830822698703\n",
      "technosphere value: -0.5 | paramater value: -0.3834705189433636\n",
      "technosphere value: -50.0 | paramater value: -44.627729228738104\n",
      "biosphere value: 1.0 | paramater value: 1.097976368881174\n",
      "* * *\n",
      "biosphere value: -1.0 | paramater value: -0.7808542075579623\n",
      "technosphere value: -0.5 | paramater value: -0.5516292981325623\n",
      "technosphere value: -50.0 | paramater value: -59.89983581508282\n",
      "biosphere value: 1.0 | paramater value: 1.2486503519675274\n",
      "* * *\n",
      "biosphere value: -1.0 | paramater value: -1.0773642194053594\n",
      "technosphere value: -0.5 | paramater value: -0.4576493128015625\n",
      "technosphere value: -50.0 | paramater value: -44.526165947418875\n",
      "biosphere value: 1.0 | paramater value: 0.9616516149663774\n",
      "* * *\n",
      "biosphere value: -1.0 | paramater value: -1.2316197229913426\n",
      "technosphere value: -0.5 | paramater value: -0.6240161058004015\n",
      "technosphere value: -50.0 | paramater value: -46.30428386774783\n",
      "biosphere value: 1.0 | paramater value: 1.2204739415654613\n",
      "* * *\n"
     ]
    }
   ],
   "source": [
    "# testing the loop that will be used for the simulation, iterate through parameter values\n",
    "    \n",
    "for i in range(0,n_iter): # iterate 5 times...\n",
    "    for s in param_samples: # and for each paramater...\n",
    "        \n",
    "        # Get the 'id' using the activity object\n",
    "        col_id = bd.Database(s[0][0]).get(s[0][1]).id\n",
    "        row_id = bd.Database(s[1][0]).get(s[1][1]).id\n",
    "        \n",
    "        # Use the id and the mapping dictionaries to find matrix row and columns\n",
    "        if s[1][0] == 'ecoinvent-3.11-biosphere':\n",
    "            col = LCA.dicts.activity[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.dicts.biosphere[row_id] # find row index of B matrix for the exchange\n",
    "            print(f\"biosphere value: {LCA.biosphere_matrix[row,col]} | paramater value: {s[2][i]}\")\n",
    "        else:\n",
    "            col = LCA.dicts.activity[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.dicts.activity[row_id] # find row index of A matrix for the exchange\n",
    "            print(f\"technosphere value: {LCA.technosphere_matrix[row,col]} | paramater value: {-s[2][i]}\") # CHANGE OF SIGN!\n",
    "        \n",
    "    print(\"* * *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial value 180.28497357367445\n",
      "end value 193.95129634385825\n",
      "---\n",
      "initial value 180.28497357367445\n",
      "end value 169.4361572696431\n",
      "---\n",
      "initial value 180.28497357367445\n",
      "end value 224.94563110865064\n",
      "---\n",
      "initial value 180.28497357367445\n",
      "end value 162.451260206448\n",
      "---\n",
      "initial value 180.28497357367445\n",
      "end value 176.49614662305444\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Implementing the loop\n",
    "import copy # a library helps to save the original matrices\n",
    "\n",
    "GSA_value_results = []\n",
    "\n",
    "for i in range(0,n_iter): \n",
    "    LCA.lci()\n",
    "    LCA.lcia()\n",
    "    print(\"initial value\", LCA.score)\n",
    "    \n",
    "    old_bio_matrix = copy.deepcopy(LCA.biosphere_matrix)\n",
    "    old_tech_matrix = copy.deepcopy(LCA.technosphere_matrix)\n",
    "    \n",
    "    for s in param_samples:\n",
    "        col_id = bd.Database(s[0][0]).get(s[0][1]).id\n",
    "        row_id = bd.Database(s[1][0]).get(s[1][1]).id\n",
    "\n",
    "        if s[1][0] == 'ecoinvent-3.11-biosphere':\n",
    "            col = LCA.dicts.activity[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.dicts.biosphere[row_id] # find row index of B matrix for the exchange\n",
    "            new_bio = s[2][i]\n",
    "            LCA.biosphere_matrix[row,col] = new_bio # substitute the value\n",
    "        else:\n",
    "            col = LCA.dicts.activity[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.dicts.activity[row_id] # find row index of A matrix for the exchange\n",
    "            new_tech = -s[2][i]\n",
    "            LCA.technosphere_matrix[row,col] = new_tech # substitute the value\n",
    "                \n",
    "    LCA.redo_lci() # uses the new A matrix\n",
    "    LCA.lcia()\n",
    "    GSA_value_results.append(LCA.score)\n",
    "    print('end value', LCA.score)\n",
    "    print(\"---\")\n",
    "\n",
    "    # Restore the original matrices\n",
    "    LCA.biosphere_matrix = old_bio_matrix\n",
    "    LCA.technosphere_matrix = old_tech_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "\n",
    "Now we have both the input and output values and we can look at their correlation.\n",
    "\n",
    "To estimate the degree of correlation use a Pearson coefficient of linear relationship between two sets of values.\n",
    "\n",
    "See here for info: \n",
    "https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n",
    "\n",
    "This approach has for example been used in:\n",
    "\n",
    "_Kim, A., Mutel, C., Froemelt, A., 2021. Robust high-dimensional screening. Environmental Modelling & Software 105270._ https://doi.org/10.1016/j.envsoft.2021.105270\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par1</th>\n",
       "      <th>par2</th>\n",
       "      <th>par3</th>\n",
       "      <th>par4</th>\n",
       "      <th>GWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>par1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.065893</td>\n",
       "      <td>0.671864</td>\n",
       "      <td>0.319435</td>\n",
       "      <td>0.781122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>par2</th>\n",
       "      <td>-0.065893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.328698</td>\n",
       "      <td>0.583272</td>\n",
       "      <td>0.410900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>par3</th>\n",
       "      <td>0.671864</td>\n",
       "      <td>0.328698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.208573</td>\n",
       "      <td>0.940491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>par4</th>\n",
       "      <td>0.319435</td>\n",
       "      <td>0.583272</td>\n",
       "      <td>0.208573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GWI</th>\n",
       "      <td>0.781122</td>\n",
       "      <td>0.410900</td>\n",
       "      <td>0.940491</td>\n",
       "      <td>0.504140</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          par1      par2      par3      par4       GWI\n",
       "par1  1.000000 -0.065893  0.671864  0.319435  0.781122\n",
       "par2 -0.065893  1.000000  0.328698  0.583272  0.410900\n",
       "par3  0.671864  0.328698  1.000000  0.208573  0.940491\n",
       "par4  0.319435  0.583272  0.208573  1.000000  0.504140\n",
       "GWI   0.781122  0.410900  0.940491  0.504140  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcualte correlation\n",
    "\n",
    "corr_data = pd.DataFrame([i[2] for i in param_samples], index = ['par1','par2', 'par3', 'par4']).T\n",
    "corr_data['GWI'] = GSA_value_results\n",
    "corr_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this specific case \"par3\"  is the parameter to which the results are most sensitive to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exchange: 50.0 kilogram 'Biobased-product-manufacturing' (kilogram, None, None) to 'Biobased-product-use' (year, None, None)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what was \"par3\" again?\n",
    "par3 # amount of manufactured product need din the use stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAST\n",
    "\n",
    "The content below shows how to perform a simple Global Sensitivity Analysis (GSA) applying the FAST, a variance-based sensitivity analysis method, for an example product system of a biobased product.\n",
    "\n",
    "Special thanks to _Pierre Jouannais_ for developing an early version of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import bw2calc as bc\n",
    "import bw2data as bd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from lci_to_bw2 import * # import all the functions of this module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a project with ecoinvent v.3.9.1 consequential system model\n",
    "bd.projects.set_current('advlca25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing data about a fictional (\"dummy\") product system for a biobased product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dummy product system\n",
    "\n",
    "# import data from csv\n",
    "mydata = pd.read_csv('ALIGNED-LCI-biobased-product-dummy.csv', header = 0, sep = \",\") # using csv file avoids encoding problem\n",
    "mydata.head()\n",
    "\n",
    "# keep only the columns not needed\n",
    "mydb = mydata[['Activity database','Activity code','Activity name','Activity unit','Activity type',\n",
    "               'Exchange database','Exchange input','Exchange amount','Exchange unit','Exchange type',\n",
    "               'Exchange uncertainty type','Exchange loc','Exchange scale','Exchange negative', 'Exchange minimum', 'Exchange maximum', \n",
    "               'Simapro name',\t'Simapro unit', 'Simapro type']].copy()\n",
    "\n",
    "mydb['Exchange uncertainty type'] = mydb['Exchange uncertainty type'].fillna(0).astype(int) # uncertainty as integers\n",
    "# Note: to avoid having both nan and values in the uncertainty column I use zero as default\n",
    "\n",
    "#print(mydb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m14:37:19\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mNot able to determine geocollections for all datasets. This database is not ready for regionalization.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 5/5 [00:00<00:00, 7463.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m14:37:19\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mVacuuming database            \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary in bw format and write database to disk. \n",
    "# Shut down all other notebooks using the same project before doing this\n",
    "bw2_db = lci_to_bw2(mydb) # a function from the lci_to_bw2 module\n",
    "\n",
    "# write database\n",
    "bd.Database('ALIGNED-biob-prod-dummy').write(bw2_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product system includes different activities such as the production, use, and end of life of the biobased product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Biobased-product-eol' (kilogram, None, None) c8301e73-d521-4a89-998b-30b7e7751011\n",
      "'Biomass-processing' (kilogram, None, None) 403a5c32-c769-46fc-8b9a-74b8eb3c79d1\n",
      "'Biobased-product-use' (year, None, None) f9eabf64-b899-40c0-9f9f-2009dbb0a0b2\n",
      "'Biomass-growth' (kilogram, None, None) a7d34649-9c10-4423-bac3-ecab9b43b20c\n",
      "'Biobased-product-manufacturing' (kilogram, None, None) a37d149a-6508-4563-8af6-e5a39b4176df\n"
     ]
    }
   ],
   "source": [
    "# check what foreground activities are included\n",
    "for act in bd.Database('ALIGNED-biob-prod-dummy'):\n",
    "    print(act, act['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Biobased-product-use',\n",
       " 'unit': 'year',\n",
       " 'type': 'processwithreferenceproduct',\n",
       " 'database': 'ALIGNED-biob-prod-dummy',\n",
       " 'code': 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2',\n",
       " 'id': 158206797701619715}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More info \n",
    "myact = bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2') # Biobased-product-use\n",
    "myact._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': ('ALIGNED-biob-prod-dummy', 'a37d149a-6508-4563-8af6-e5a39b4176df'),\n",
       " 'amount': 50.0,\n",
       " 'unit': 'kilogram',\n",
       " 'type': 'technosphere',\n",
       " 'uncertainty type': 4,\n",
       " 'minimum': 37.5,\n",
       " 'maximum': 62.5,\n",
       " 'Simapro name': 'Biobased-product-manufacturing',\n",
       " 'Simapro unit': 'kg',\n",
       " 'output': ('ALIGNED-biob-prod-dummy', 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncertainty is also there\n",
    "list(myact.exchanges())[1]._data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate a static climate impact score for the fictional biobased product, to be used for reference later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180.28497357367445\n"
     ]
    }
   ],
   "source": [
    "# calculation of static LCA score\n",
    "mymethod = ('ecoinvent-3.11', 'IPCC 2021', 'climate change: fossil', 'global warming potential (GWP100)')\n",
    "myact = bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2') # Biobased-product-use\n",
    "functional_unit = {myact: 1}\n",
    "LCA = bc.LCA(functional_unit, mymethod)\n",
    "LCA.lci()\n",
    "LCA.lcia()\n",
    "print(LCA.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now perform sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure is in three steps.\n",
    "\n",
    "1) A set of model input parameters is chosen. These are **values of specific exchanges**. A sample of values is produced for each model input **using a specific and efficient sampling design** (the **\"problem\"** below)\n",
    "2) A simulation is performed. Initial prameter values are substituted with those in the sample, iteratively, and new model outputs, that are LCA scores, are calculated.\n",
    "3) **A sensitivity index is calculated** using model input values (the \"problem\") and output values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "Obtain a sample of values for each parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a  pseudo-random sample obtained using a sampling method from the SALib package on the problem previously defined.\n",
    "\n",
    "it is defined as a __FAST__ sample (\"Fourier Amplitude Sensitivity Analysis\"), another alternative to Sobol method.\n",
    "\n",
    "Sobol and FAST sampling methods use different pseudo-random patterns to cover the space of parameters, and different calculations for the sensitivity indices.\n",
    "\n",
    "Besides these differences, the (extended) FAST method is, just like the Sobol one, a variance-based method for sensitivity analysis. It provides the same information as the Sobol method but with higher computational efficiency.\n",
    "\n",
    "For further information and comparison see: \n",
    "\n",
    "_Saltelli, A.; Tarantola, S.; Chan, K. P. S. A Quantitative Model-Independent Method for Global Sensitivity Analysis of Model Output. Technometrics 1999, 41 (1), 39–56._ https://doi.org/10.1080/00401706.1999.10485594.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you run the next cell __you need to install the SALib library!__\n",
    "\n",
    "Please do `conda install SALib` in the brightway environment´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to import the SALib library and relaive methods for sensitvity analysis\n",
    "# do 'conda install SALib' in the brightway environment\n",
    "\n",
    "from SALib.sample import saltelli\n",
    "from SALib.sample import fast_sampler\n",
    "from SALib.analyze import sobol\n",
    "from SALib.analyze import fast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the \"problem\" for the GSA analysis as indicated in the SALib library.\n",
    "Uniform distributions for the uncertainty of for each input parameter are here assumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = { 'num_vars': 4, # number of variables\n",
    "            'names': ['par1', 'par2', 'par3', 'par4'], # names of variables, same as parameters\n",
    "            'bounds': [[-1.25, -0.75], # careful here to what is the lower bound with negative values...\n",
    "                       [0.1, 0.9],  \n",
    "                       [20, 60],\n",
    "                       [0.75, 1.25]] ,\n",
    "           'dists':[\"unif\",\"unif\",\"unif\",\"unif\"] } # all uniform distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.78929891,  0.83712175, 56.85608747,  1.21070109],\n",
       "       [-0.90929891,  0.82912175, 56.05608747,  1.19570109],\n",
       "       [-1.02929891,  0.82112175, 55.25608747,  1.18070109],\n",
       "       ...,\n",
       "       [-0.9134298 ,  0.66251231, 49.32561571,  1.0684298 ],\n",
       "       [-0.9184298 ,  0.64651231, 48.12561571,  1.1884298 ],\n",
       "       [-0.9234298 ,  0.63051231, 46.92561571,  1.1915702 ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FAST sampler creates N*P parameters sets with N=sample size, P = number of parameters\n",
    "param_values_FAST = fast_sampler.sample(problem, 200)\n",
    "print(param_values_FAST.shape)\n",
    "\n",
    "param_values_FAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate the values to specific exchanges using the coordinates (column and row) of the technosphere (A) and biosphere (B) matrices, taking the data directly from the BW database that we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In biomass growth, value of CO2 uptake\n",
    "par1 = list(bd.Database('ALIGNED-biob-prod-dummy').get('a7d34649-9c10-4423-bac3-ecab9b43b20c').exchanges())[3]\n",
    "# In biomass processing, amount of energy used.\n",
    "par2 = list(bd.Database('ALIGNED-biob-prod-dummy').get('403a5c32-c769-46fc-8b9a-74b8eb3c79d1').exchanges())[1]\n",
    "# In use of product, amount of manufactured product needed\n",
    "par3 = list(bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2').exchanges())[1]\n",
    "# In use of product, amount of manufactured product needed\n",
    "par4 = list(bd.Database('ALIGNED-biob-prod-dummy').get('c8301e73-d521-4a89-998b-30b7e7751011').exchanges())[2]\n",
    "\n",
    "n_iter = len(param_values_FAST)\n",
    "param_samples = [(par1['output'],par1['input'], [i[0] for i in param_values_FAST]),\n",
    "                 (par2['output'],par2['input'], [i[1] for i in param_values_FAST]),\n",
    "                 (par3['output'],par3['input'], [i[2] for i in param_values_FAST]),\n",
    "                 (par4['output'],par4['input'], [i[3] for i in param_values_FAST])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "\n",
    "Iteration through all parameter samples. New LCA scores are calculated for each combination of values.\n",
    "\n",
    "With 800 iterations, **this will take some time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Implementing the loop (This cell will take some time to run)\n",
    "import copy # a library helps to save the original matrices\n",
    "\n",
    "GSA_value_results = []\n",
    "\n",
    "for i in range(0,len(param_values_FAST)): \n",
    "    LCA.lci()\n",
    "    LCA.lcia()\n",
    "    print(\"initial value\", LCA.score)\n",
    "    \n",
    "    old_bio_matrix = copy.deepcopy(LCA.biosphere_matrix)\n",
    "    old_tech_matrix = copy.deepcopy(LCA.technosphere_matrix)\n",
    "    \n",
    "    for s in param_samples:\n",
    "        # Get the 'id' using the activity object\n",
    "        col_id = bd.Database(s[0][0]).get(s[0][1]).id\n",
    "        row_id = bd.Database(s[1][0]).get(s[1][1]).id\n",
    "        \n",
    "        # Use the id and the mapping dictionaries to find matrix row and columns\n",
    "        if s[1][0] == 'ecoinvent-3.11-biosphere':\n",
    "            col = LCA.dicts.activity[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.dicts.biosphere[row_id] # find row index of B matrix for the exchange\n",
    "            LCA.biosphere_matrix[row,col] = s[2][i] # substitute the value\n",
    "        else:\n",
    "            col = LCA.dicts.activity[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.dicts.activity[row_id] # find row index of A matrix for the exchange\n",
    "            LCA.technosphere_matrix[row,col] = -s[2][i] # substitute the value\n",
    "        \n",
    "    LCA.redo_lci() # uses the new A matrix\n",
    "    LCA.lcia()\n",
    "    GSA_value_results.append(LCA.score)\n",
    "    print('end value', LCA.score)\n",
    "    print(\"---\")\n",
    "\n",
    "    # Restore original matrices\n",
    "    LCA.biosphere_matrix = old_bio_matrix\n",
    "    LCA.technosphere_matrix = old_tech_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "\n",
    "Now we have both the input and output values and we can feed the problem and the results to the Sobol function to obtain the FAST indices.\n",
    "\n",
    "First we look at the parameters and the result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par0</th>\n",
       "      <th>par1</th>\n",
       "      <th>par2</th>\n",
       "      <th>par3</th>\n",
       "      <th>GWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.789299</td>\n",
       "      <td>0.837122</td>\n",
       "      <td>56.856087</td>\n",
       "      <td>1.210701</td>\n",
       "      <td>214.906975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.909299</td>\n",
       "      <td>0.829122</td>\n",
       "      <td>56.056087</td>\n",
       "      <td>1.195701</td>\n",
       "      <td>208.626490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.029299</td>\n",
       "      <td>0.821122</td>\n",
       "      <td>55.256087</td>\n",
       "      <td>1.180701</td>\n",
       "      <td>202.442248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.149299</td>\n",
       "      <td>0.813122</td>\n",
       "      <td>54.456087</td>\n",
       "      <td>1.165701</td>\n",
       "      <td>196.354249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.230701</td>\n",
       "      <td>0.805122</td>\n",
       "      <td>53.656087</td>\n",
       "      <td>1.150701</td>\n",
       "      <td>191.397996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.110701</td>\n",
       "      <td>0.797122</td>\n",
       "      <td>52.856087</td>\n",
       "      <td>1.135701</td>\n",
       "      <td>191.829774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.990701</td>\n",
       "      <td>0.789122</td>\n",
       "      <td>52.056087</td>\n",
       "      <td>1.120701</td>\n",
       "      <td>192.165795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.870701</td>\n",
       "      <td>0.781122</td>\n",
       "      <td>51.256087</td>\n",
       "      <td>1.105701</td>\n",
       "      <td>192.406059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.750701</td>\n",
       "      <td>0.773122</td>\n",
       "      <td>50.456087</td>\n",
       "      <td>1.090701</td>\n",
       "      <td>192.550566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.869299</td>\n",
       "      <td>0.765122</td>\n",
       "      <td>49.656087</td>\n",
       "      <td>1.075701</td>\n",
       "      <td>186.675399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       par0      par1       par2      par3         GWI\n",
       "0 -0.789299  0.837122  56.856087  1.210701  214.906975\n",
       "1 -0.909299  0.829122  56.056087  1.195701  208.626490\n",
       "2 -1.029299  0.821122  55.256087  1.180701  202.442248\n",
       "3 -1.149299  0.813122  54.456087  1.165701  196.354249\n",
       "4 -1.230701  0.805122  53.656087  1.150701  191.397996\n",
       "5 -1.110701  0.797122  52.856087  1.135701  191.829774\n",
       "6 -0.990701  0.789122  52.056087  1.120701  192.165795\n",
       "7 -0.870701  0.781122  51.256087  1.105701  192.406059\n",
       "8 -0.750701  0.773122  50.456087  1.090701  192.550566\n",
       "9 -0.869299  0.765122  49.656087  1.075701  186.675399"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organize data first to give a look at what we have done: a sample of input values and a corresponding output value\n",
    "fast_data = pd.DataFrame([i[2] for i in param_samples], index = ['par0','par1', 'par2', 'par3']).T\n",
    "fast_data['GWI'] = GSA_value_results\n",
    "fast_data.head(10) # show only the first ten samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the SI index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            S1        ST   S1_conf   ST_conf\n",
      "par1  0.008741  0.009749  0.084121  0.079559\n",
      "par2  0.000032  0.000875  0.074418  0.091467\n",
      "par3  0.933678  0.936661  0.072216  0.103028\n",
      "par4  0.055244  0.057548  0.068082  0.090582\n"
     ]
    }
   ],
   "source": [
    "si = fast.analyze(problem, np.array(GSA_value_results), print_to_console=True) # must use np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this specific case \"par3\"  is the parameter to which the results are most sensitive to, this because it has the highest value for \"S1\" which is the first order effect.\n",
    "\n",
    "This is determined with relativelygood confidence as the error (value of \"S1_conf\") is small compared to the coefficient.\n",
    "\n",
    "Note also that \"par3\" is also the parameter withi highest sensitivity in the total model, i.e. when in combinatino with other parameters, as observed by the highest value of \"ST\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exchange: 50.0 kilogram 'Biobased-product-manufacturing' (kilogram, None, None) to 'Biobased-product-use' (year, None, None)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this specific case \"par3\" is the parameter to which the results ar emost sensitive to, and values have high confidente (small error)\n",
    "# what was \"par3\" again?\n",
    "par3 # amount of manufactured product need din the use stage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
